{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "99f673c9",
   "metadata": {},
   "source": [
    "# English to Dutch translation using the opus book dataset and marianMT tranformer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61542884",
   "metadata": {},
   "source": [
    "### Loading the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59975d5c",
   "metadata": {},
   "source": [
    "The dataset is downloaded directly from the hugging face library interface using the 'datasets' library.</br>\n",
    "Once downloaded the dataset will be present in the cache memory of the notebook and can be accessed for future use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5cb8f63e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset opus_books (C:\\Users\\Sharanya Manohar\\.cache\\huggingface\\datasets\\opus_books\\en-nl\\1.0.0\\e8f950a4f32dc39b7f9088908216cd2d7e21ac35f893d04d39eb594746af2daf)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b93f120656340d4a5668a2aa5d6f7b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'translation'],\n",
       "        num_rows: 38652\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Downloading opus_books dataset \n",
    "from datasets import load_dataset, load_metric\n",
    "raw_data = load_dataset(\"opus_books\", \"en-nl\")\n",
    "raw_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "524b2840",
   "metadata": {},
   "source": [
    "The dataset is available in a single split and needs to be split to create a validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b499fe4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached split indices for dataset at C:\\Users\\Sharanya Manohar\\.cache\\huggingface\\datasets\\opus_books\\en-nl\\1.0.0\\e8f950a4f32dc39b7f9088908216cd2d7e21ac35f893d04d39eb594746af2daf\\cache-7c291857a01d0ef1.arrow and C:\\Users\\Sharanya Manohar\\.cache\\huggingface\\datasets\\opus_books\\en-nl\\1.0.0\\e8f950a4f32dc39b7f9088908216cd2d7e21ac35f893d04d39eb594746af2daf\\cache-50aba06ad647e377.arrow\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'translation'],\n",
       "        num_rows: 34786\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'translation'],\n",
       "        num_rows: 3866\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_data = raw_data[\"train\"].train_test_split(train_size=0.9, seed=20)\n",
    "split_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5d915d5",
   "metadata": {},
   "source": [
    "'test' key can be renamed as 'validation' for interpretability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "163e1eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_data[\"validation\"] = split_data.pop(\"test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b90b1e1",
   "metadata": {},
   "source": [
    "Let us look at one instance of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4ef5d4f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'en': 'That was a good time.\"', 'nl': 'Dat was een goede tijd.\"'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_data[\"train\"][1][\"translation\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59407cfe",
   "metadata": {},
   "source": [
    "### Defining the tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2de71025",
   "metadata": {},
   "source": [
    "Pre-defined tokenizer of the pre-trained \"opus-mt-en-nl\" model by Helsinki NLP is used to tokenize the text in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "22e6ea78",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_marianMT = \"Helsinki-NLP/opus-mt-en-nl\"\n",
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_marianMT,use_fast=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4f80d825",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Unlike t5 transformer , marian MT does not require an aciton prefix\n",
    "prefix = \"\" "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c3f8018",
   "metadata": {},
   "source": [
    "### Defining the pre-processing function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7d0cbc1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Refer hugging face documentations for language codes\n",
    "source_language = \"en\"\n",
    "target_language = \"nl\"\n",
    "\n",
    "max_input_length = 128\n",
    "max_target_length = 128\n",
    "\n",
    "def preprocess(instances):\n",
    "   input = [prefix + i[source_language] for i in instances[\"translation\"]]\n",
    "   target = [i[target_language] for i in instances[\"translation\"]]\n",
    "   tokenized_inputs = tokenizer(input, max_length=max_input_length, truncation=True)\n",
    "   # Setup the tokenizer for target\n",
    "   with tokenizer.as_target_tokenizer():\n",
    "       label = tokenizer(target, max_length=max_target_length, truncation=True)\n",
    "   tokenized_inputs[\"labels\"] = label[\"input_ids\"]\n",
    "   return tokenized_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6994dc29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d01e98bb29dd44ee9d3196aafd8e15bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/35 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d65a1723d6e34cf2bad0d03dfb059da0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Applying the pre processing on the entire dataset\n",
    "tokenized_datasets = split_data.map(preprocess, batched=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66846cd8",
   "metadata": {},
   "source": [
    "### Creating subsets of the dataset for faster training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "66e391e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tokenized_datasets[\"train\"].shuffle(seed=42).select(range(1000))\n",
    "eval_dataset = tokenized_datasets[\"validation\"].shuffle(seed=42).select(range(1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "045c146c",
   "metadata": {},
   "source": [
    "### Using the 'marianMT' pre-trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a2ca7372",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM, DataCollatorForSeq2Seq, Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_marianMT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "73534e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "\n",
    "#defining training attributes\n",
    "args = Seq2SeqTrainingArguments(\n",
    "   output_dir=\"./results\",\n",
    "   evaluation_strategy = \"epoch\",\n",
    "   learning_rate=2e-5,\n",
    "   per_device_train_batch_size=batch_size,\n",
    "   per_device_eval_batch_size=batch_size,\n",
    "   weight_decay=0.01,\n",
    "   save_total_limit=3,\n",
    "   num_train_epochs=1,\n",
    "   predict_with_generate=True   \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d8b075e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pad inputs and label them\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1442637d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to C:\\Users\\Sharanya\n",
      "[nltk_data]     Manohar\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to C:\\Users\\Sharanya\n",
      "[nltk_data]     Manohar\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to C:\\Users\\Sharanya\n",
      "[nltk_data]     Manohar\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from datasets import load_metric\n",
    "metric = load_metric(\"sacrebleu\")\n",
    "meteor = load_metric('meteor')\n",
    "\n",
    "#customizing compute_metrics function to display bleu score, mean prediction length and meteor score\n",
    "def compute_metrics(eval_preds):\n",
    "   preds, labels = eval_preds\n",
    "   if isinstance(preds, tuple):\n",
    "       preds = preds[0]\n",
    "    \n",
    "   decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
    "   # Replacing -100 in the labels as they are not needed and cannot be decoded\n",
    "   labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "   decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "   \n",
    "   decoded_preds = [pred.strip() for pred in decoded_preds]\n",
    "   decoded_labels = [[label.strip()] for label in decoded_labels]\n",
    "   \n",
    "   result = metric.compute(predictions=decoded_preds, references=decoded_labels)\n",
    "   meteor_result = meteor.compute(predictions=decoded_preds, references=decoded_labels)\n",
    "   prediction_length = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in preds]\n",
    "   \n",
    "   result = {'bleu' : result['score']}\n",
    "   result[\"gen_len\"] = np.mean(prediction_length)\n",
    "   result[\"meteor\"] = meteor_result[\"meteor\"]\n",
    "   result = {x: round(y, 4) for x, y in result.items()}\n",
    "   return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "853026ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#training object with customized parameters\n",
    "trainer = Seq2SeqTrainer(\n",
    "   model,\n",
    "   args,\n",
    "   train_dataset=train_dataset,\n",
    "   eval_dataset=eval_dataset,\n",
    "   data_collator=data_collator,\n",
    "   tokenizer=tokenizer,\n",
    "   compute_metrics=compute_metrics\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5a7d66a2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the training set  don't have a corresponding argument in `MarianMTModel.forward` and have been ignored: id, translation. If id, translation are not expected by `MarianMTModel.forward`,  you can safely ignore this message.\n",
      "C:\\Users\\Sharanya Manohar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 1000\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 63\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='63' max='63' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [63/63 48:20, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Bleu</th>\n",
       "      <th>Gen Len</th>\n",
       "      <th>Meteor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>2.513342</td>\n",
       "      <td>14.721800</td>\n",
       "      <td>32.105000</td>\n",
       "      <td>0.325300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set  don't have a corresponding argument in `MarianMTModel.forward` and have been ignored: id, translation. If id, translation are not expected by `MarianMTModel.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1000\n",
      "  Batch size = 16\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=63, training_loss=2.736075507269965, metrics={'train_runtime': 2917.0953, 'train_samples_per_second': 0.343, 'train_steps_per_second': 0.022, 'total_flos': 23336905605120.0, 'train_loss': 2.736075507269965, 'epoch': 1.0})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train model using train function\n",
    "trainer.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
