{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cd1d161b",
   "metadata": {},
   "source": [
    "# English to German translation using the wmt16 dataset and marianMT tranformer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8900b56",
   "metadata": {},
   "source": [
    "### Loading the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3b57dff",
   "metadata": {},
   "source": [
    "The dataset is downloaded directly from the hugging face library interface using the 'datasets' library.</br>\n",
    "Once downloaded the dataset will be present in the cache memory of the notebook and can be accessed for future use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "def1dfd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset wmt16 (C:\\Users\\Sharanya Manohar\\.cache\\huggingface\\datasets\\wmt16\\de-en\\1.0.0\\9e0038fe4cc117bd474d2774032cc133e355146ed0a47021b2040ca9db4645c0)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef9411fb5e4940b4be1aa5808ebf7a50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['translation'],\n",
       "        num_rows: 4548885\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['translation'],\n",
       "        num_rows: 2169\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['translation'],\n",
       "        num_rows: 2999\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Downloading wmt16 dataset \n",
    "from datasets import load_dataset, load_metric\n",
    "raw_data = load_dataset(\"wmt16\", \"de-en\")\n",
    "raw_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba463835",
   "metadata": {},
   "source": [
    "### Defining the tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c590dbe7",
   "metadata": {},
   "source": [
    "Pre-defined tokenizer of the pre-trained \"opus-mt-en-de\" model by Helsinki NLP is used to tokenize the text in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dbb4b97f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_marianMT = \"Helsinki-NLP/opus-mt-en-de\"\n",
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_marianMT,use_fast=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3755ad6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Unlike t5 transformer , marian MT does not require an aciton prefix\n",
    "prefix = \"\" "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0527002",
   "metadata": {},
   "source": [
    "### Defining the pre-processing function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7c4ca746",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Refer hugging face documentations for language codes\n",
    "source_language = \"en\"\n",
    "target_language = \"de\"\n",
    "\n",
    "max_input_length = 128\n",
    "max_target_length = 128\n",
    "\n",
    "def preprocess(instances):\n",
    "   input = [prefix + i[source_language] for i in instances[\"translation\"]]\n",
    "   target = [i[target_language] for i in instances[\"translation\"]]\n",
    "   tokenized_inputs = tokenizer(input, max_length=max_input_length, truncation=True)\n",
    "   # Setup the tokenizer for target\n",
    "   with tokenizer.as_target_tokenizer():\n",
    "       label = tokenizer(target, max_length=max_target_length, truncation=True)\n",
    "   tokenized_inputs[\"labels\"] = label[\"input_ids\"]\n",
    "   return tokenized_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "755bb2d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "243cd052399d4546886943d4abda6c3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4549 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93eb390a926d452299636cd6cd97df05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ce014cd202c44eca98fc80779756c32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Applying the pre processing on the entire dataset\n",
    "tokenized_datasets = raw_data.map(preprocess, batched=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b15d5056",
   "metadata": {},
   "source": [
    "### Creating subsets of the dataset for faster training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e77da716",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tokenized_datasets[\"train\"].shuffle(seed=42).select(range(1000))\n",
    "eval_dataset = tokenized_datasets[\"test\"].shuffle(seed=42).select(range(1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3a158ec",
   "metadata": {},
   "source": [
    "### Using the 'marianMT' pre-trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e1572ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM, DataCollatorForSeq2Seq, Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_marianMT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "80b93d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "\n",
    "#defining training attributes\n",
    "args = Seq2SeqTrainingArguments(\n",
    "   output_dir=\"./results\",\n",
    "   evaluation_strategy = \"epoch\",\n",
    "   learning_rate=2e-5,\n",
    "   per_device_train_batch_size=batch_size,\n",
    "   per_device_eval_batch_size=batch_size,\n",
    "   weight_decay=0.01,\n",
    "   save_total_limit=3,\n",
    "   num_train_epochs=1,\n",
    "   predict_with_generate=True   \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8dfd7b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pad inputs and label them\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "30684c9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to C:\\Users\\Sharanya\n",
      "[nltk_data]     Manohar\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to C:\\Users\\Sharanya\n",
      "[nltk_data]     Manohar\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to C:\\Users\\Sharanya\n",
      "[nltk_data]     Manohar\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from datasets import load_metric\n",
    "metric = load_metric(\"sacrebleu\")\n",
    "meteor = load_metric('meteor')\n",
    "\n",
    "#customizing compute_metrics function to display bleu score, mean prediction length and meteor score\n",
    "def compute_metrics(eval_preds):\n",
    "   preds, labels = eval_preds\n",
    "   if isinstance(preds, tuple):\n",
    "       preds = preds[0]\n",
    "    \n",
    "   decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
    "   # Replacing -100 in the labels as they are not needed and cannot be decoded\n",
    "   labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "   decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "   \n",
    "   decoded_preds = [pred.strip() for pred in decoded_preds]\n",
    "   decoded_labels = [[label.strip()] for label in decoded_labels]\n",
    "   \n",
    "   result = metric.compute(predictions=decoded_preds, references=decoded_labels)\n",
    "   meteor_result = meteor.compute(predictions=decoded_preds, references=decoded_labels)\n",
    "   prediction_length = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in preds]\n",
    "   \n",
    "   result = {'bleu' : result['score']}\n",
    "   result[\"gen_len\"] = np.mean(prediction_length)\n",
    "   result[\"meteor\"] = meteor_result[\"meteor\"]\n",
    "   result = {x: round(y, 4) for x, y in result.items()}\n",
    "   return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3508d3ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#training object with customized parameters\n",
    "trainer = Seq2SeqTrainer(\n",
    "   model,\n",
    "   args,\n",
    "   train_dataset=train_dataset,\n",
    "   eval_dataset=eval_dataset,\n",
    "   data_collator=data_collator,\n",
    "   tokenizer=tokenizer,\n",
    "   compute_metrics=compute_metrics\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "38dd3429",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the training set  don't have a corresponding argument in `MarianMTModel.forward` and have been ignored: translation. If translation are not expected by `MarianMTModel.forward`,  you can safely ignore this message.\n",
      "C:\\Users\\Sharanya Manohar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 1000\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 63\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='63' max='63' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [63/63 33:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Bleu</th>\n",
       "      <th>Gen Len</th>\n",
       "      <th>Meteor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.173238</td>\n",
       "      <td>36.381300</td>\n",
       "      <td>26.842000</td>\n",
       "      <td>0.501200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set  don't have a corresponding argument in `MarianMTModel.forward` and have been ignored: translation. If translation are not expected by `MarianMTModel.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1000\n",
      "  Batch size = 16\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=63, training_loss=2.1024366106305803, metrics={'train_runtime': 1991.2929, 'train_samples_per_second': 0.502, 'train_steps_per_second': 0.032, 'total_flos': 19455542820864.0, 'train_loss': 2.1024366106305803, 'epoch': 1.0})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train model using train function \n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b364a063",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
